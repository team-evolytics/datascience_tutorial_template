{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c44b094b",
   "metadata": {},
   "source": [
    "# Template for Data Science Party Tutorials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d506ab",
   "metadata": {},
   "source": [
    "# Preface - Installing Packages \n",
    "\n",
    "## Using Jupyter Notebooks \n",
    "\n",
    "Jupyter Notebooks is an interactive Python environment for data science.   Cells are seperated into Markdown (i.e., text) and code cells.  In this notebook, you should not need to edit code (unless you really want to!). Therefore, you can just run each cell by highlighting it and pressing \"Cmd + Return\" or using the \"> Run\" key at the top.\n",
    "\n",
    "Note: A best practice is to import packages in the first cell of the notebook.  However, given that this is a tutorial packages will be imported in the first cell in which they are used to more closely associate the package with it's use.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ba32a3",
   "metadata": {},
   "source": [
    "## Installing Packages \n",
    "First, we'll install some packages we'll use in the tutorial today. This may produce a lot of output so please be patient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57e508c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install libraries if not present. \n",
    "\n",
    "# Use magic commands to import libraries (e.g., !pip install <librairy name>)\n",
    "\n",
    "\n",
    "# Import libraries into our environment. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b359ee",
   "metadata": {},
   "source": [
    "## 1. Import our Data\n",
    "\n",
    "We're going to use pandas to import and inspect our data.  We will also preview the data to allow users to understand the nature of the variables they are working with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf425424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas \n",
    "import pandas as pd \n",
    "\n",
    "# Import data here as df \n",
    "\n",
    "# Inspect our dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c425a27f",
   "metadata": {},
   "source": [
    "## 2. Pre-processing of Data \n",
    "\n",
    "This section should be used for any required precessing of text.  If the data needs to be cleaned, have missing values replaced or dropped, or be formatted as a numpy array that should occur here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1180f461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "# Preprocessing Code "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78017d5",
   "metadata": {},
   "source": [
    "Sometimes preprocessing functions are not clear in what they're doing.  If so, call the function below so that the user gets some idea of the data transformations occuring.  When relevant include code that demonstrates the datas shape or other key characteristics.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625f8d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "# Preprocessing Code goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90ed463",
   "metadata": {},
   "source": [
    "### Splitting Data \n",
    "\n",
    "If the data should have a train/test split (i.e.,  you are demonstrating a supervised learning technique) split the data here.  Note that even if you are demoing an unsupervised learning technique you may still wish to split the data to demonstrate how the model behaves with unseen data.  Delete this section at your own discretion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbd82d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split our data. \n",
    "df_train, df_test = train_test_split(df, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2e7b47",
   "metadata": {},
   "source": [
    "### Feature Extraction \n",
    " \n",
    "In order to prevent data leakage, you may wish to do features extraction after the train test split. Data leakage is when information from the test split is present in the training data.  For example, if you calculated a metrics that used a variables mean, you would want to use the mean from the training set not the entire dataset.  To do otherwise, uses information from the test dataset. The need for this should be determined on a case-by-case basis for the given technique.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5268f840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "# Feature extraction code goes here. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a350412f",
   "metadata": {},
   "source": [
    "# 3.  Model Creation:  < MODEL NAME >\n",
    "\n",
    "Describe in the simplest terms possible: \n",
    "   - What the model is doing\n",
    "   - What assumptions the model makes\n",
    "   - Any requirements for the data \n",
    "    \n",
    "Spell out any common abbreviations when introduced.  For example: \n",
    "   - Stochastic Gradient Descent (SGD) \n",
    "   - Non-Negative Matrix Factorization (NMF) \n",
    "   - Recurrent Neural Network (RNN) \n",
    "   \n",
    "Note that some models may not be able to be trained on the issued laptops or may take to long to train.  Include the code showing how it would be trained and then use the functions in the appendix to import the trained model (e.g., weights etc).  In otherwords, even if we can't train the model live, can we get the model into memory to demonstrate it's capabilities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68377d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We're going to time our training to know if it's feasible for a demo.  Shoot\n",
    "for 5 minutes but no more than 10.  You can assume that most Concord issued \n",
    "laptops have simliar computing specficiations. \n",
    "\"\"\"\n",
    "%%time\n",
    "\n",
    "\n",
    "# Fit model \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b54c6c3",
   "metadata": {},
   "source": [
    "# 4.  Model Inspection \n",
    "\n",
    "Provide a demonstration of what the mode has actually done. This may be demonstrating model outputs or predictions.  The goal here is to show the practical import of the model - what has it allowed us to do.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f59374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model inspection code.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72aa6fa",
   "metadata": {},
   "source": [
    "# 5.  Assessing Unseen Data \n",
    "\n",
    "Demonstrate how the model handles unseen data.  This may involve calling predict or transform on unseen data under sk-learn.  How does it behave or perform?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b480ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to assess unseen data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7191c306",
   "metadata": {},
   "source": [
    "# 6. Visualization of Results \n",
    "\n",
    "How could we visualize results? Provide at least one simple method that allows for quick visual insight into the data.  You may wish to mention other, non-implemented, techniques that could be used for visualization or the types of questions you could ask of the data/model that would make for good visualizations.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcc8982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to visualize data here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67235654",
   "metadata": {},
   "source": [
    "# 6. Conclusion\n",
    "\n",
    "Provide: \n",
    "\n",
    "1. A recap of what they learned. \n",
    "2. Resources to follow up for learning more. \n",
    "3. Encouragement to use the code for their own work. \n",
    "\n",
    "\n",
    "Please feel free to use the above code for your own projects.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d71f9f",
   "metadata": {},
   "source": [
    "# Appendix I - Model taking too long to train? \n",
    "\n",
    "Note that github has a file size limit so it is often not possible to put all objects in a single dictionary, pickle it, and push it to github.  Therefore, it's recommended that you save each object to a seperate pickle file in the saved_model folder.   The below cell allows a user to read the file back in.  \n",
    "\n",
    "**Copy for this cell:** \n",
    "\n",
    "Having trouble getting the model to run in the time allotted for the tutorial? Fortunately, Python has a module \"pickle\" that allows for the storage of objects.  I've written a version of the model featured in this notebook to file that you can read it in to finish our exercise. \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663a698b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "# specify the file names.  \n",
    "files = [\n",
    "]\n",
    "\n",
    "# Set file path. \n",
    "path = os.getcwd()+\"/saved_model/\"\n",
    "\n",
    "model_data = {}\n",
    "\n",
    "# Read in pickle files. \n",
    "for f in files: \n",
    "    with open(path+f, 'rb') as file:\n",
    "        model_data[f] = pickle.load(file)\n",
    "\n",
    "# You may have to read in pandas dataframes using native methods. \n",
    "# Example: pd.read_csv(path+'dataframe.csv')     \n",
    "\n",
    "# Assign objects as they are assigned in the tutorial above so that the user can continue without training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5c43a4",
   "metadata": {},
   "source": [
    "# Appendix II - Want to save your model? \n",
    "\n",
    "Have you tweaked the above script and want to save your own model to file? Run the cell below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d1f003",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "import os \n",
    "\n",
    "# Set file path. \n",
    "path = os.getcwd()+\"/saved_model/\"\n",
    "if not os.path.isdir(path): \n",
    "   os.mkdir(path)\n",
    "\n",
    "# Use built in methods to save dataframes if possible. \n",
    "# Example: df_train.to_csv(path+'df_train.csv') \n",
    "\n",
    "\n",
    "# Specify objects to save to file as a dictionary.  The key will be used as the file name while \n",
    "# the value is the object.\n",
    "files = {\n",
    "}\n",
    "\n",
    "# Write objects to file. \n",
    "for k,v in files.items(): \n",
    "    with open(path+k, 'wb') as file:\n",
    "        pickle.dump(v, file)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cabe6bd",
   "metadata": {},
   "source": [
    "## Appendix III - Getting Code on People's Computer\n",
    "\n",
    "\n",
    "The proper way to get this onto code onto a user's computer is with git. However, we want to ensure that people that do not have git installed or are not familiar \n",
    "can easily download the tutorial hence the use of built in python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77dad194",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from io import BytesIO\n",
    "from urllib.request import urlopen\n",
    "from zipfile import ZipFile\n",
    "\n",
    "zipurl = 'https://github.com/team-evolytics/data_science_party_nlp_tutorial/archive/refs/heads/main.zip'\n",
    "\n",
    "with urlopen(zipurl) as zipresp:\n",
    "    with ZipFile(BytesIO(zipresp.read())) as zfile:\n",
    "        zfile.extractall(os.getcwd())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
